{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def dtw_to_similarity(dtw_distance, alpha=1):\n",
    "    \"\"\"将两个序列之间的 DTW 距离转换为相似度（0，1）之间\"\"\"\n",
    "    return np.exp(-dtw_distance / alpha)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T10:18:57.789260900Z",
     "start_time": "2023-12-21T10:18:57.773429900Z"
    }
   },
   "id": "b0b82b0556ec8c27"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Distance  Similarity\n640  0.471580    0.624016\n644  0.433374    0.648318\n646  0.363169    0.695469\n647  0.358055    0.699035\n648  0.498053    0.607713\n649  0.507061    0.602263\n650  0.493409    0.610541\n651  0.504463    0.603830\n652  0.499434    0.606874\n653  0.432469    0.648905\n654  0.456532    0.633477\n655  0.436222    0.646474\n656  0.420645    0.656623\n657  0.439124    0.644601\n658  0.503150    0.604623\n878  0.467971    0.626272\n879  0.445441    0.640542\n881  0.501891    0.605385\n882  0.487624    0.614084\n883  0.447713    0.639088\n884  0.464454    0.628478",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Distance</th>\n      <th>Similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>640</th>\n      <td>0.471580</td>\n      <td>0.624016</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>0.433374</td>\n      <td>0.648318</td>\n    </tr>\n    <tr>\n      <th>646</th>\n      <td>0.363169</td>\n      <td>0.695469</td>\n    </tr>\n    <tr>\n      <th>647</th>\n      <td>0.358055</td>\n      <td>0.699035</td>\n    </tr>\n    <tr>\n      <th>648</th>\n      <td>0.498053</td>\n      <td>0.607713</td>\n    </tr>\n    <tr>\n      <th>649</th>\n      <td>0.507061</td>\n      <td>0.602263</td>\n    </tr>\n    <tr>\n      <th>650</th>\n      <td>0.493409</td>\n      <td>0.610541</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>0.504463</td>\n      <td>0.603830</td>\n    </tr>\n    <tr>\n      <th>652</th>\n      <td>0.499434</td>\n      <td>0.606874</td>\n    </tr>\n    <tr>\n      <th>653</th>\n      <td>0.432469</td>\n      <td>0.648905</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>0.456532</td>\n      <td>0.633477</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>0.436222</td>\n      <td>0.646474</td>\n    </tr>\n    <tr>\n      <th>656</th>\n      <td>0.420645</td>\n      <td>0.656623</td>\n    </tr>\n    <tr>\n      <th>657</th>\n      <td>0.439124</td>\n      <td>0.644601</td>\n    </tr>\n    <tr>\n      <th>658</th>\n      <td>0.503150</td>\n      <td>0.604623</td>\n    </tr>\n    <tr>\n      <th>878</th>\n      <td>0.467971</td>\n      <td>0.626272</td>\n    </tr>\n    <tr>\n      <th>879</th>\n      <td>0.445441</td>\n      <td>0.640542</td>\n    </tr>\n    <tr>\n      <th>881</th>\n      <td>0.501891</td>\n      <td>0.605385</td>\n    </tr>\n    <tr>\n      <th>882</th>\n      <td>0.487624</td>\n      <td>0.614084</td>\n    </tr>\n    <tr>\n      <th>883</th>\n      <td>0.447713</td>\n      <td>0.639088</td>\n    </tr>\n    <tr>\n      <th>884</th>\n      <td>0.464454</td>\n      <td>0.628478</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tslearn.metrics import dtw_path\n",
    "from dataset.dataset import load_data\n",
    "from utils.util import calc_dtw\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df, test_times = load_data('../dataset/tanjiaoyi/sh_carbon.csv')\n",
    "print(len(df))\n",
    "# Standardize 'close' and 'Daily_EPU' columns\n",
    "scaler = MinMaxScaler()\n",
    "df[['close', 'Daily_EPU']] = scaler.fit_transform(df[['close', 'Daily_EPU']])\n",
    "\n",
    "# Initialize lists to store results\n",
    "distances = []\n",
    "similarities = []\n",
    "\n",
    "# Sliding window size and step\n",
    "window_size = 30\n",
    "step = 1\n",
    "\n",
    "# Apply sliding window\n",
    "for start in range(len(df) - window_size + 1):\n",
    "    end = start + window_size\n",
    "    sub_df = df[start:end]\n",
    "    \n",
    "    # Calculate DTW distance and similarity\n",
    "    distance, similarity = calc_dtw(sub_df['close'], sub_df['Daily_EPU'])\n",
    "    # sim = dtw_to_similarity(similarity)\n",
    "    distances.append(distance)\n",
    "    similarities.append(similarity)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame({'Distance': distances, 'Similarity': similarities})\n",
    "\n",
    "# Filtering the DataFrame for similarity values greater than 0.7\n",
    "high_similarity_df = results_df[results_df['Similarity'] > 0.6]\n",
    "\n",
    "# Display the filtered results\n",
    "high_similarity_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T10:21:50.997145800Z",
     "start_time": "2023-12-21T10:21:50.430806200Z"
    }
   },
   "id": "fb7a71b2b0c0ad88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
